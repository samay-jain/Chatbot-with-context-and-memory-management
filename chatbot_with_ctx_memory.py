import json
import requests
from typing import Dict, List

def create_initial_messages() -> List[Dict[str, str]]:
    """
    Create the initial message history for the chatbot session.
    
    Returns:
        A list containing one system message that sets the tone or context 
        for the conversation.
    """
    return [{"role": "system", "content": "Hello, how can I help you today?"}]

def chat(user_input: str, messages: List[Dict[str, str]], model_name: str) -> str:
    """
    Sends a chat request to the local Ollama chat API and retrieves the assistant's response.

    Args:
        user_input: The input message from the user.
        messages: The current list of chat history (context) including all prior messages.
        model_name: The identifier for the language model to use (e.g., "llama3.2").

    Returns:
        The response content generated by the model, or an error message if the request fails.
    """
    # Add the user's input to the conversation history
    messages.append({"role": "user", "content": user_input})

    # Format the payload for the POST request
    payload = {
        "model": model_name,
        "messages": messages
    }

    try:
        # Send the request to the local Ollama API
        response = requests.post("http://localhost:11434/api/chat", json=payload)

        if response.status_code == 200:
            full_response = ""
            # Read the streaming response line-by-line
            for line in response.iter_lines(decode_unicode=True):
                if line:
                    try:
                        json_data = json.loads(line)
                        # Append model's response content if present
                        if "message" in json_data and "content" in json_data["message"]:
                            full_response += json_data["message"]["content"]
                    except json.JSONDecodeError:
                        # Handle the case where the line isn't valid JSON
                        print(f"\nFailed to parse line: {line}")
            # Add the assistant's full response to the message history
            messages.append({"role": "assistant", "content": full_response})
            return full_response
        else:
            # Return error response with status code
            return f"Error: {response.status_code}\n{response.text}"
    except Exception as e:
        # Catch any other exceptions (e.g., connection issues)
        return f"Exception occurred: {str(e)}"

def summarize_messages(messages: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    Summarizes the last few messages in the conversation to reduce memory/token usage.

    Args:
        messages: The current list of all messages in the conversation.

    Returns:
        A new message list starting with a system summary followed by the last few messages.
    """
    # Create a basic summary of the last 5 messages
    summary = "Previous conversation summarized: " + " ".join(
        [m["content"][:50] + "..." for m in messages[-5:]]
    )
    # Return a new list starting with the summary and ending with the last 5 messages
    return [{"role": "system", "content": summary}] + messages[-5:]

def save_conversation(messages: List[Dict[str, str]], filename: str = "conversation.json"):
    """
    Saves the current conversation history to a JSON file.

    Args:
        messages: The list of messages to be saved.
        filename: The name of the file where the messages will be stored.
    """
    with open(filename, "w") as f:
        json.dump(messages, f)

def load_conversation(filename: str = "conversation.json") -> List[Dict[str, str]]:
    """
    Loads a conversation history from a JSON file.

    Args:
        filename: The name of the file to read from.

    Returns:
        The loaded message list. If the file is not found, returns a default initial message list.
    """
    try:
        with open(filename, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        # Handle missing file by creating a new conversation context
        print(f"No conversation file found at {filename}")
        return create_initial_messages()

def main():
    """
    Entry point for the chatbot application. Handles the user interaction loop,
    interprets special commands, and manages conversation flow.
    """
    model_name = "llama3.2"  # Specify the name of the model to use
    messages = create_initial_messages()

    print("Your chatbot is initialized and is ready to chat, type 'quit' to exit.")
    print("Available commands:")
    print("- 'save': Save conversation")
    print("- 'load': Load conversation")
    print("- 'summary': Summarize conversation")

    # Main loop to continuously interact with the user
    while True:
        user_input = input("\nYou: ")

        if user_input.lower() == 'quit':
            # Exit the chat loop
            break
        elif user_input.lower() == 'save':
            # Save conversation to file
            save_conversation(messages)
            print("Conversation saved!")
            continue
        elif user_input.lower() == 'load':
            # Load conversation from file
            messages = load_conversation()
            print("Conversation loaded!")
            continue
        elif user_input.lower() == 'summary':
            # Summarize conversation
            messages = summarize_messages(messages)
            print("Conversation summarized!")
            continue

        # Generate and print model response
        response = chat(user_input, messages, model_name)
        print(f"\nAssistant: {response}")

        # Automatically summarize if conversation history grows too long
        if len(messages) > 10:
            messages = summarize_messages(messages)
            print("\n(Conversation automatically summarized)")

# Run the chatbot if this script is executed directly
if __name__ == "__main__":
    main()
